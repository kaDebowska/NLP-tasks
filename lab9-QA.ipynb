{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T22:08:12.066847Z",
     "iopub.status.busy": "2025-01-10T22:08:12.066322Z",
     "iopub.status.idle": "2025-01-10T22:08:15.519855Z",
     "shell.execute_reply": "2025-01-10T22:08:15.519044Z",
     "shell.execute_reply.started": "2025-01-10T22:08:12.066818Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.1+cu121)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.44.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.34.2)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install peft huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T22:08:15.521867Z",
     "iopub.status.busy": "2025-01-10T22:08:15.521511Z",
     "iopub.status.idle": "2025-01-10T22:08:18.724800Z",
     "shell.execute_reply": "2025-01-10T22:08:18.723962Z",
     "shell.execute_reply.started": "2025-01-10T22:08:15.521833Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.27.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T22:08:18.726026Z",
     "iopub.status.busy": "2025-01-10T22:08:18.725767Z",
     "iopub.status.idle": "2025-01-10T22:08:25.805127Z",
     "shell.execute_reply": "2025-01-10T22:08:25.804420Z",
     "shell.execute_reply.started": "2025-01-10T22:08:18.726006Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T14:22:23.128504Z",
     "start_time": "2025-01-17T14:22:14.222159Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "import evaluate\n",
    "import torch\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T22:08:25.806462Z",
     "iopub.status.busy": "2025-01-10T22:08:25.805950Z",
     "iopub.status.idle": "2025-01-10T22:08:25.837577Z",
     "shell.execute_reply": "2025-01-10T22:08:25.836654Z",
     "shell.execute_reply.started": "2025-01-10T22:08:25.806436Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T14:22:29.406114Z",
     "start_time": "2025-01-17T14:22:29.379507Z"
    }
   },
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load poquad data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T22:08:25.839887Z",
     "iopub.status.busy": "2025-01-10T22:08:25.839654Z",
     "iopub.status.idle": "2025-01-10T22:08:27.201335Z",
     "shell.execute_reply": "2025-01-10T22:08:27.200337Z",
     "shell.execute_reply.started": "2025-01-10T22:08:25.839867Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T14:22:33.506633Z",
     "start_time": "2025-01-17T14:22:32.804300Z"
    }
   },
   "source": [
    "with open(\"poquad-train.json\", 'r', encoding=\"utf8\") as file:\n",
    "    train_data = json.load(file)['data']\n",
    "with open(\"poquad-dev.json\", 'r', encoding=\"utf8\") as file:\n",
    "    val_data = json.load(file)['data']"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T22:08:27.203172Z",
     "iopub.status.busy": "2025-01-10T22:08:27.202831Z",
     "iopub.status.idle": "2025-01-10T22:08:27.208326Z",
     "shell.execute_reply": "2025-01-10T22:08:27.207471Z",
     "shell.execute_reply.started": "2025-01-10T22:08:27.203147Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T14:22:35.348800Z",
     "start_time": "2025-01-17T14:22:35.343035Z"
    }
   },
   "source": [
    "def prepare_data(data):\n",
    "    processed_data = []\n",
    "    for entry in data:\n",
    "        for paragraph in entry['paragraphs']:\n",
    "            context = paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                question = qa['question']\n",
    "                answer = \"\"\n",
    "                if 'answers' in qa and qa['answers']:\n",
    "                    answer_obj = qa['answers'][0]\n",
    "                    answer = answer_obj.get('generative_answer', answer_obj.get('text', \"\"))\n",
    "                elif 'plausible_answers' in qa and qa['plausible_answers']:\n",
    "                    answer_obj = qa['plausible_answers'][0]\n",
    "                    answer = answer_obj.get('generative_answer', answer_obj.get('text', \"\"))\n",
    "                processed_data.append({\n",
    "                    \"input\": f\"context: {context} question: {question}\",\n",
    "                    \"output\": answer\n",
    "                })\n",
    "    return processed_data"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T22:08:27.209363Z",
     "iopub.status.busy": "2025-01-10T22:08:27.209067Z",
     "iopub.status.idle": "2025-01-10T22:08:28.367337Z",
     "shell.execute_reply": "2025-01-10T22:08:28.366138Z",
     "shell.execute_reply.started": "2025-01-10T22:08:27.209332Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T14:22:40.020626Z",
     "start_time": "2025-01-17T14:22:39.287008Z"
    }
   },
   "source": [
    "train_dataset = prepare_data(train_data)\n",
    "val_dataset = prepare_data(val_data)\n",
    "\n",
    "with open(\"prepared_train.json\", \"w\", encoding='utf-8') as file:\n",
    "    json.dump(train_dataset, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "with open(\"prepared_val.json\", \"w\", encoding='utf-8') as file:\n",
    "    json.dump(val_dataset, file, indent=4,  ensure_ascii=False)\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T22:08:28.368632Z",
     "iopub.status.busy": "2025-01-10T22:08:28.368281Z",
     "iopub.status.idle": "2025-01-10T22:08:30.308879Z",
     "shell.execute_reply": "2025-01-10T22:08:30.308254Z",
     "shell.execute_reply.started": "2025-01-10T22:08:28.368594Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T14:22:42.605358Z",
     "start_time": "2025-01-17T14:22:40.738040Z"
    }
   },
   "source": [
    "train_data = load_dataset('json', data_files='prepared_train.json', split='train')\n",
    "val_data = load_dataset('json', data_files='prepared_val.json', split='train')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "723a507eca87453d8e9bda9979d61587"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6889c82c2b747c594418d13f6615a76"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T10:43:03.721826Z",
     "start_time": "2025-01-13T10:43:03.719049Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T22:08:30.310161Z",
     "iopub.status.busy": "2025-01-10T22:08:30.309819Z",
     "iopub.status.idle": "2025-01-10T22:08:30.315099Z",
     "shell.execute_reply": "2025-01-10T22:08:30.314222Z",
     "shell.execute_reply.started": "2025-01-10T22:08:30.310129Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'context: Projekty konfederacji zaczęły się załamywać 5 sierpnia 1942. Ponownie wróciła kwestia monachijska, co uaktywniło się wymianą listów Ripka – Stroński. Natomiast 17 sierpnia 1942 doszło do spotkania E. Beneša i J. Masaryka z jednej a Wł. Sikorskiego i E. Raczyńskiego z drugiej strony. Polscy dyplomaci zaproponowali podpisanie układu konfederacyjnego. W następnym miesiącu, tj. 24 września, strona polska przesłała na ręce J. Masaryka projekt deklaracji o przyszłej konfederacji obu państw. Strona czechosłowacka projekt przyjęła, lecz już w listopadzie 1942 E. Beneš podważył ideę konfederacji. W zamian zaproponowano zawarcie układu sojuszniczego z Polską na 20 lat (formalnie nastąpiło to 20 listopada 1942). question: Co było powodem powrócenia konceptu porozumieniu monachijskiego?', 'output': 'wymiana listów Ripka – Stroński'}\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T22:08:30.316075Z",
     "iopub.status.busy": "2025-01-10T22:08:30.315727Z",
     "iopub.status.idle": "2025-01-10T22:09:36.755843Z",
     "shell.execute_reply": "2025-01-10T22:09:36.754388Z",
     "shell.execute_reply.started": "2025-01-10T22:08:30.316044Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T14:23:16.785764Z",
     "start_time": "2025-01-17T14:22:45.867923Z"
    }
   },
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('allegro/plt5-base')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples['input'], padding='max_length', truncation=True, max_length=512)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        outputs = tokenizer(examples['output'], padding='max_length', truncation=True, max_length=128)\n",
    "    \n",
    "    inputs['labels'] = outputs['input_ids']\n",
    "    return inputs\n",
    "    \n",
    "\n",
    "train_data = train_data.map(tokenize_function, batched=True)\n",
    "val_data = val_data.map(tokenize_function, batched=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/56618 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88edb50c74b646ceb598ee07c69f918c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/7060 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf86a9e481684c31a393e235c8090116"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T10:43:34.434604Z",
     "start_time": "2025-01-13T10:43:34.430602Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T22:09:36.757090Z",
     "iopub.status.busy": "2025-01-10T22:09:36.756724Z",
     "iopub.status.idle": "2025-01-10T22:09:36.763245Z",
     "shell.execute_reply": "2025-01-10T22:09:36.762327Z",
     "shell.execute_reply.started": "2025-01-10T22:09:36.757054Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'context: Projekty konfederacji zaczęły się załamywać 5 sierpnia 1942. Ponownie wróciła kwestia monachijska, co uaktywniło się wymianą listów Ripka – Stroński. Natomiast 17 sierpnia 1942 doszło do spotkania E. Beneša i J. Masaryka z jednej a Wł. Sikorskiego i E. Raczyńskiego z drugiej strony. Polscy dyplomaci zaproponowali podpisanie układu konfederacyjnego. W następnym miesiącu, tj. 24 września, strona polska przesłała na ręce J. Masaryka projekt deklaracji o przyszłej konfederacji obu państw. Strona czechosłowacka projekt przyjęła, lecz już w listopadzie 1942 E. Beneš podważył ideę konfederacji. W zamian zaproponowano zawarcie układu sojuszniczego z Polską na 20 lat (formalnie nastąpiło to 20 listopada 1942). question: Co było powodem powrócenia konceptu porozumieniu monachijskiego?', 'output': 'wymiana listów Ripka – Stroński', 'input_ids': [12634, 22091, 399, 291, 2958, 273, 19605, 6869, 271, 298, 2256, 7465, 394, 540, 2142, 259, 17542, 13760, 10331, 9511, 322, 31220, 261, 358, 348, 267, 7243, 430, 470, 271, 39908, 20622, 2178, 18204, 308, 8439, 2451, 259, 1974, 455, 540, 2142, 1283, 272, 994, 525, 259, 15697, 1978, 267, 264, 644, 259, 14988, 19434, 265, 1109, 287, 274, 357, 259, 21308, 264, 525, 259, 35197, 305, 265, 793, 823, 259, 25318, 2750, 4724, 31015, 21207, 4162, 40335, 18058, 259, 274, 4862, 7030, 261, 5269, 259, 658, 497, 261, 6971, 1890, 35042, 267, 266, 3260, 644, 259, 14988, 19434, 1187, 20919, 284, 27584, 19605, 1230, 2555, 259, 12531, 7278, 3845, 8726, 10486, 1187, 10676, 261, 996, 347, 260, 2548, 2142, 525, 259, 15697, 1978, 309, 27648, 31887, 19605, 259, 274, 4931, 36525, 37011, 4162, 10036, 7141, 265, 6340, 266, 465, 346, 269, 3648, 4383, 6704, 294, 465, 567, 2142, 454, 277, 18616, 4767, 291, 639, 402, 11586, 292, 23822, 267, 1269, 8741, 280, 24310, 42404, 305, 373, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [13862, 20622, 2178, 18204, 308, 8439, 2451, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:35:21.586354Z",
     "start_time": "2025-01-13T11:35:18.876135Z"
    }
   },
   "outputs": [],
   "source": [
    "config = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM,  r=16, lora_alpha=16, lora_dropout=0.1)\n",
    "model = T5ForConditionalGeneration.from_pretrained('allegro/plt5-base').to(device)\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:36:04.476112Z",
     "start_time": "2025-01-13T11:36:04.402187Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T22:11:07.359037Z",
     "iopub.status.busy": "2025-01-10T22:11:07.358631Z",
     "iopub.status.idle": "2025-01-10T22:11:09.257989Z",
     "shell.execute_reply": "2025-01-10T22:11:09.257317Z",
     "shell.execute_reply.started": "2025-01-10T22:11:07.359006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_total_limit=3,\n",
    "    save_steps=1000, \n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:36:07.760052Z",
     "start_time": "2025-01-13T11:36:07.757625Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T22:11:15.766524Z",
     "iopub.status.busy": "2025-01-10T22:11:15.766156Z",
     "iopub.status.idle": "2025-01-10T22:11:15.770513Z",
     "shell.execute_reply": "2025-01-10T22:11:15.769559Z",
     "shell.execute_reply.started": "2025-01-10T22:11:15.766492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:36:08.722249Z",
     "start_time": "2025-01-13T11:36:08.708792Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T22:11:21.838144Z",
     "iopub.status.busy": "2025-01-10T22:11:21.837788Z",
     "iopub.status.idle": "2025-01-10T22:11:21.842093Z",
     "shell.execute_reply": "2025-01-10T22:11:21.841285Z",
     "shell.execute_reply.started": "2025-01-10T22:11:21.838114Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:36:11.226399Z",
     "start_time": "2025-01-13T11:36:11.144217Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T22:12:00.158478Z",
     "iopub.status.busy": "2025-01-10T22:12:00.158149Z",
     "iopub.status.idle": "2025-01-10T22:12:00.609893Z",
     "shell.execute_reply": "2025-01-10T22:12:00.609258Z",
     "shell.execute_reply.started": "2025-01-10T22:12:00.158454Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:47:15.796834Z",
     "start_time": "2025-01-13T11:36:24.199534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7076' max='7076' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7076/7076 4:10:49, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>95.692400</td>\n",
       "      <td>41.791786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>8.991800</td>\n",
       "      <td>7.595444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>6.955500</td>\n",
       "      <td>6.186247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>5.755900</td>\n",
       "      <td>4.864702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>4.505900</td>\n",
       "      <td>3.662211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.706600</td>\n",
       "      <td>3.097040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.557200</td>\n",
       "      <td>2.929034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7076, training_loss=23.558995421017677, metrics={'train_runtime': 15051.4084, 'train_samples_per_second': 7.523, 'train_steps_per_second': 0.47, 'total_flos': 8.292752218600243e+16, 'train_loss': 23.558995421017677, 'epoch': 1.999646755448797})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:34:38.872042Z",
     "start_time": "2025-01-13T16:34:38.128123Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"./final_model2\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T14:23:22.288613Z",
     "start_time": "2025-01-17T14:23:16.789771Z"
    }
   },
   "source": [
    "config = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM,  r=16, lora_alpha=16, lora_dropout=0.1)\n",
    "model_path = \"./final_model2\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path).to(device)\n",
    "model = get_peft_model(model, config)\n",
    "tokenizer = T5Tokenizer.from_pretrained('allegro/plt5-base')"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:23:22.333997Z",
     "start_time": "2025-01-17T14:23:22.331088Z"
    }
   },
   "source": [
    "import re\n",
    "\n",
    "# Funkcja do oczyszczania odpowiedzi modelu z nieoczekiwanych znaków\n",
    "def clean_text(text):\n",
    "    pattern = r'[^a-zA-ZąćęłńóśżźĄĆĘŁŃÓŚŻŹ0-9.,!?;:\\'\"() ]'\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    \n",
    "    return cleaned_text"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:23:22.380715Z",
     "start_time": "2025-01-17T14:23:22.377343Z"
    }
   },
   "source": [
    "def get_predictions(data, model, tokenizer, device='cuda'):\n",
    "    predictions = []\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    for input_text, output_text in zip(data['input'], data['output']):\n",
    "        question = input_text.split(\"question:\")[1].strip()\n",
    "        context = input_text.split(\"context:\")[1].split(\"question:\")[0].strip()\n",
    "\n",
    "        inputs = tokenizer(question, context, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=inputs['input_ids'], \n",
    "            attention_mask=inputs['attention_mask'], \n",
    "            max_length=128\n",
    "        )\n",
    "\n",
    "        prediction = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        prediction = clean_text(prediction)\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    return predictions\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:23:30.949907Z",
     "start_time": "2025-01-17T14:23:30.946921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_question(input_text):\n",
    "    return input_text.split(\"question:\")[-1].strip()"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:23:34.930937Z",
     "start_time": "2025-01-17T14:23:32.714856Z"
    }
   },
   "source": [
    "squad_metric = evaluate.load(\"squad\")\n",
    "\n",
    "def compute_metrics(predictions, references):\n",
    "\n",
    "    formatted_references = [{\"id\": str(i), \"answers\": {\"text\": [ref], \"answer_start\": [0]}} for i, ref in enumerate(references)]\n",
    "    formatted_predictions = [{\"id\": str(i), \"prediction_text\": pred} for i, pred in enumerate(predictions)]\n",
    "    \n",
    "    results = squad_metric.compute(predictions=formatted_predictions, references=formatted_references)\n",
    "    \n",
    "    return results"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:48:53.865060Z",
     "start_time": "2025-01-17T14:23:50.777924Z"
    }
   },
   "source": [
    "predictions = get_predictions(val_data, model, tokenizer)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:48:53.884319Z",
     "start_time": "2025-01-17T14:48:53.870064Z"
    }
   },
   "source": [
    "references = val_data['output']"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:15:47.866614Z",
     "start_time": "2025-01-13T11:15:47.862899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba próbek w predictions: 7060\n",
      "Liczba próbek w references: 7060\n"
     ]
    }
   ],
   "source": [
    "print(f\"Liczba próbek w predictions: {len(predictions)}\")\n",
    "print(f\"Liczba próbek w references: {len(references)}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:48:54.317453Z",
     "start_time": "2025-01-17T14:48:53.929033Z"
    }
   },
   "source": [
    "predictions_text = [item for item in predictions]\n",
    "references_text = [item for item in references] \n",
    "\n",
    "metrics = compute_metrics(predictions_text, references_text)\n",
    "\n",
    "print(metrics)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_match': 0.09915014164305949, 'f1': 4.577592185746859}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Example results on validation dataset"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:48:54.412937Z",
     "start_time": "2025-01-17T14:48:54.398062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random \n",
    "for i in range(10):\n",
    "    index = random.randint(0, len(predictions))\n",
    "    question = extract_question(val_data[index][\"input\"])\n",
    "    print(f\"Question: {question}\")\n",
    "    prediction = predictions_text[index]\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    reference = references_text[index]\n",
    "    print(f\"Reference: {reference}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Jaki bramkarz zastąpił Szczęsnego po jego odejściu z Juventusu?\n",
      "Prediction:  w lidze włoskiej. Wojciech Szczęsny w Juventusie.\n",
      "Reference: Gianluigi Donnarumma\n",
      "Question: Z jaką zawodniczką wygrała Novotna w półfinale?\n",
      "Prediction:  w finale z Hingis.\n",
      "Reference: Martiną Hingis\n",
      "Question: Na jakich aspektach miał skupić się, jako ambasador USA w Polsce, zgodnie z jego przemówieniem z końca 2021 roku?\n",
      "Prediction:  w Polsce, a nie w Polsce.. Marek Brzeziński, jako ambasador USA w Polsce\n",
      "Reference: bezstronnym sądownictwie, niezależnych mediach i poszanowaniu praw człowieka dla wszystkich, w tym osób LGBTQI+ i członków innych mniejszości\n",
      "Question: Jaki był budżet filmu \"Wszystko o Stevenie\"?\n",
      "Prediction:  w 2009 roku. \"Wszystko o Stevenie\":\n",
      "Reference: 33,8 mln dol\n",
      "Question: W jakim mieście rozgrywa się akcja wszystkich ekranizacji Moralności pani Dulskiej?\n",
      "Prediction:  w Krakowie. W jakim mieście rozgrywa się akcja wszystkich ekranizacji?\n",
      "Reference: Krakowie\n",
      "Question: Na czym polegał Project Possible?\n",
      "Prediction:  w 2018 roku. Plan został zrealizowany.\n",
      "Reference: zdobycie korony Himalajów i Karakorum\n",
      "Question: Jakie wydawnictwa odmówiły rejestracji herbu z dołączonymi trzymaczami i postumentem?\n",
      "Prediction:  w Polsce. W Polsce. W Polsce. W Polsce. W Polsce. W Polsce.\n",
      "Reference: ukraińskie i bułgarskie\n",
      "Question: Jacy artyści służyli za jej muzyczne inspiracje?\n",
      "Prediction: .pl  Wywiady  Wywiady prasowe\n",
      "Reference: głównie Billie Holiday, Madonna, Dusty Springfield i Missy Elliott\n",
      "Question: Który raz gracze rywalizowali ze sobą o tytuł mistrza świata?\n",
      "Prediction: .. Wayne..\n",
      "Reference: czwarty\n",
      "Question: Jakie działanie wykonywał kalkulator przy podwójnym wciśnięciu klawisza MRC?\n",
      "Prediction:  MRC, MRC, MRC.\n",
      "Reference: drugim kasował pamięć\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best results on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:15:48.518434Z",
     "start_time": "2025-01-13T11:15:48.512587Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics_for_examples(predictions, references, val_data):\n",
    "    formatted_references = [{\"id\": str(i), \"answers\": {\"text\": [ref], \"answer_start\": [0]}} for i, ref in enumerate(references)]\n",
    "    formatted_predictions = [{\"id\": str(i), \"prediction_text\": pred} for i, pred in enumerate(predictions)]\n",
    "    \n",
    "    example_metrics = []\n",
    "    for i, (pred, ref) in enumerate(zip(formatted_predictions, formatted_references)):\n",
    "        result = squad_metric.compute(predictions=[pred], references=[ref])\n",
    "        question = extract_question(val_data[i][\"input\"])\n",
    "        \n",
    "        example_metrics.append({\n",
    "            \"id\": pred[\"id\"],\n",
    "            \"question\": question,\n",
    "            \"prediction\": pred[\"prediction_text\"],\n",
    "            \"reference\": ref[\"answers\"][\"text\"][0],\n",
    "            \"exact_match\": result[\"exact_match\"],\n",
    "            \"f1\": result[\"f1\"]\n",
    "        })\n",
    "    \n",
    "    return example_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T17:01:27.355633Z",
     "start_time": "2025-01-13T17:00:16.484899Z"
    }
   },
   "outputs": [],
   "source": [
    "example_metrics = compute_metrics_for_examples(predictions_text, references_text, val_data)\n",
    "\n",
    "df_metrics = pd.DataFrame(example_metrics)\n",
    "\n",
    "sorted_by_f1 = df_metrics.sort_values(by=\"f1\", ascending=False)\n",
    "sorted_by_em = df_metrics.sort_values(by=\"exact_match\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:16:57.651802Z",
     "start_time": "2025-01-13T11:16:57.648331Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_top_examples(sorted_df, metric, top_n):\n",
    "    print(f\"Top {top_n} examples with highest {metric}:\")\n",
    "    for i, row in sorted_df.head(top_n).iterrows():\n",
    "        print(f\"\\nExample {i + 1}:\")\n",
    "        print(f\"Question: {row['question']}\")\n",
    "        print(f\"Prediction: {row['prediction']}\")\n",
    "        print(f\"Reference: {row['reference']}\")\n",
    "        print(f\"{metric}: {row[metric]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T17:01:27.413734Z",
     "start_time": "2025-01-13T17:01:27.411055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 examples with highest f1:\n",
      "\n",
      "Example 381:\n",
      "Question: Gdzie znajdowała się posiadłość Wybickiego?\n",
      "Prediction:  w Manieczkach.\n",
      "Reference: w Manieczkach\n",
      "f1: 100.00\n",
      "\n",
      "Example 1158:\n",
      "Question: Gdzie Drygin był klasyfikowany na 73. pozycji w supergigancie?\n",
      "Prediction:  w Les Orres?\n",
      "Reference: w Les Orres\n",
      "f1: 100.00\n",
      "\n",
      "Example 2110:\n",
      "Question: W jakiej miejscowości powstał klasztor stworzony z myślą o Rognedzie?\n",
      "Prediction:  w Izasławiu.\n",
      "Reference: w Izasławiu\n",
      "f1: 100.00\n",
      "\n",
      "Example 1671:\n",
      "Question: W jakim mieście miał miejsce pierwszy festiwal reggae?\n",
      "Prediction:  w Montego Bay?\n",
      "Reference: w Montego Bay\n",
      "f1: 100.00\n",
      "\n",
      "Example 4933:\n",
      "Question: Gdzie przeprowadzono pierwsze testy w locie unowocześnionej wersji tego modelu?\n",
      "Prediction:  w Kapustin Jarze.\n",
      "Reference: w Kapustin Jarze\n",
      "f1: 100.00\n",
      "\n",
      "Example 3387:\n",
      "Question: Jakie relikwie zostały przywiezione do Łucka?\n",
      "Prediction:  św. Recessa Męczennika.\n",
      "Reference: św. Recessa Męczennika\n",
      "f1: 100.00\n",
      "\n",
      "Example 6665:\n",
      "Question: Jaki utwór był reprezentacyjny dla krążka 1991?\n",
      "Prediction:  Lawa?\n",
      "Reference: Lawa\n",
      "f1: 100.00\n",
      "\n",
      "Example 6524:\n",
      "Question: Jaki oddział przejął generał Thommé?\n",
      "Prediction: .. I dywizjon 16 pułku artylerii lekkiej. II dywizjon.\n",
      "Reference: I dywizjon 16 pułku artylerii lekkiej\n",
      "f1: 85.71\n",
      "\n",
      "Example 5813:\n",
      "Question: W jakim miesiącu kraje położone na północ od równika przestawiają czas o godzinę do przodu?\n",
      "Prediction:  w marcu lub kwietniu?\n",
      "Reference: marcu lub kwietniu\n",
      "f1: 85.71\n",
      "\n",
      "Example 1862:\n",
      "Question: W jakim celu był wykorzystywany U-2?\n",
      "Prediction: . U2 jako jednostka szkolna.\n",
      "Reference: jako jednostka szkolna\n",
      "f1: 85.71\n"
     ]
    }
   ],
   "source": [
    "display_top_examples(sorted_by_f1, 'f1', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T17:01:27.465894Z",
     "start_time": "2025-01-13T17:01:27.461734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 examples with highest exact_match:\n",
      "\n",
      "Example 1158:\n",
      "Question: Gdzie Drygin był klasyfikowany na 73. pozycji w supergigancie?\n",
      "Prediction:  w Les Orres?\n",
      "Reference: w Les Orres\n",
      "exact_match: 100.00\n",
      "\n",
      "Example 4933:\n",
      "Question: Gdzie przeprowadzono pierwsze testy w locie unowocześnionej wersji tego modelu?\n",
      "Prediction:  w Kapustin Jarze.\n",
      "Reference: w Kapustin Jarze\n",
      "exact_match: 100.00\n",
      "\n",
      "Example 2110:\n",
      "Question: W jakiej miejscowości powstał klasztor stworzony z myślą o Rognedzie?\n",
      "Prediction:  w Izasławiu.\n",
      "Reference: w Izasławiu\n",
      "exact_match: 100.00\n",
      "\n",
      "Example 6665:\n",
      "Question: Jaki utwór był reprezentacyjny dla krążka 1991?\n",
      "Prediction:  Lawa?\n",
      "Reference: Lawa\n",
      "exact_match: 100.00\n",
      "\n",
      "Example 381:\n",
      "Question: Gdzie znajdowała się posiadłość Wybickiego?\n",
      "Prediction:  w Manieczkach.\n",
      "Reference: w Manieczkach\n",
      "exact_match: 100.00\n",
      "\n",
      "Example 1671:\n",
      "Question: W jakim mieście miał miejsce pierwszy festiwal reggae?\n",
      "Prediction:  w Montego Bay?\n",
      "Reference: w Montego Bay\n",
      "exact_match: 100.00\n",
      "\n",
      "Example 3387:\n",
      "Question: Jakie relikwie zostały przywiezione do Łucka?\n",
      "Prediction:  św. Recessa Męczennika.\n",
      "Reference: św. Recessa Męczennika\n",
      "exact_match: 100.00\n",
      "\n",
      "Example 4714:\n",
      "Question: Jaką funkcję sprawował w \"Przeglądzie Sportowym\" od 2001 roku?\n",
      "Prediction:  w Polsce. \"Przegląd Sportowy\" w liczbach: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "Reference: zastępcy redaktora naczelnego\n",
      "exact_match: 0.00\n",
      "\n",
      "Example 4708:\n",
      "Question: Co stało się z siódmą generacją tego samochodu pod koniec 2005 roku?\n",
      "Prediction:  w tym roku. Fiesta po liftingu\n",
      "Reference: przeszła lifting\n",
      "exact_match: 0.00\n",
      "\n",
      "Example 4713:\n",
      "Question: Czy ten film jest adaptacją komiksu?\n",
      "Prediction: .pl  Filmy  Wonder Woman.\n",
      "Reference: tak\n",
      "exact_match: 0.00\n"
     ]
    }
   ],
   "source": [
    "display_top_examples(sorted_by_em, 'exact_match', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:53:27.572813Z",
     "start_time": "2025-01-17T14:53:27.423374Z"
    }
   },
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def load_jsonl(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        return [json.loads(line) for line in file]\n",
    "\n",
    "answers = load_jsonl(\"answers.jl\")\n",
    "passages = load_jsonl(\"passages.jl\")\n",
    "relevant = load_jsonl(\"relevant.jl\")\n",
    "questions = load_jsonl(\"questions.jl\")\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:53:28.953508Z",
     "start_time": "2025-01-17T14:53:28.914056Z"
    }
   },
   "source": [
    "answers = [a for a in answers if a[\"score\"] == \"1\"]\n",
    "\n",
    "passages_dict = {p[\"_id\"]: p[\"text\"] for p in passages}\n",
    "questions_dict = {q[\"_id\"]: q[\"text\"] for q in questions}\n",
    "\n",
    "data = []\n",
    "for rel in relevant:\n",
    "    passage_text = passages_dict[rel[\"passage-id\"]]\n",
    "    question_text = questions_dict[rel[\"question-id\"]]\n",
    "    answer = next((a[\"answer\"] for a in answers if a[\"question-id\"] == rel[\"question-id\"]), None)\n",
    "    \n",
    "    if answer:\n",
    "        data.append({\n",
    "            \"input\": f\"context: {passage_text} question: {question_text}\",\n",
    "            \"output\": answer\n",
    "        })\n",
    "\n",
    "\n",
    "test_dataset = Dataset.from_dict({\"input\": [d[\"input\"] for d in data], \"output\": [d[\"output\"] for d in data]})\n",
    "\n",
    "print(test_dataset)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input', 'output'],\n",
      "    num_rows: 573\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'context: Art. 345. § 1. Żołnierz, który dopuszcza się czynnej napaści na przełożonego, podlega karze aresztu wojskowego albo pozbawienia wolności do lat 3. § 2. Jeżeli sprawca dopuszcza się czynnej napaści w związku z pełnieniem przez przełożonego obowiązków służbowych albo wspólnie z innymi żołnierzami lub w obecności zebranych żołnierzy, podlega karze pozbawienia wolności od 6 miesięcy do lat 8. § 3. Jeżeli sprawca czynu określonego w § 1 lub 2 używa broni, noża lub innego podobnie niebezpiecznego przedmiotu, podlega karze pozbawienia wolności od roku do lat 10. § 4. Karze przewidzianej w § 3 podlega sprawca czynu określonego w § 1 lub 2, jeżeli jego następstwem jest skutek określony w art. 156 lub 157 § 1. question: Czy żołnierz, który dopuszcza się czynnej napaści na przełożonego podlega karze pozbawienia wolności?',\n",
       " 'output': 'Tak, podlega karze aresztu wojskowego albo pozbawienia wolności do lat 3.'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:55:42.212757Z",
     "start_time": "2025-01-17T14:53:34.983114Z"
    }
   },
   "source": [
    "predictions_test = get_predictions(test_dataset, model, tokenizer)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:55:42.221689Z",
     "start_time": "2025-01-17T14:55:42.216763Z"
    }
   },
   "source": [
    "references_test = test_dataset['output']"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:55:42.314102Z",
     "start_time": "2025-01-17T14:55:42.269061Z"
    }
   },
   "source": [
    "predictions_test_text = [item for item in predictions_test]\n",
    "references_test_text = [item for item in references_test] \n",
    "\n",
    "metrics_test = compute_metrics(predictions_test_text, references_test_text)\n",
    "\n",
    "print(metrics_test)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_match': 0.6980802792321117, 'f1': 9.064270335651074}\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Example results on test dataset"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:55:42.363407Z",
     "start_time": "2025-01-17T14:55:42.359377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(10):\n",
    "    index = random.randint(0, len(predictions_test_text))\n",
    "    question = extract_question(test_dataset[index][\"input\"])\n",
    "    print(f\"Question: {question}\")\n",
    "    prediction = predictions_test_text[index]\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    reference = references_test_text[index]\n",
    "    print(f\"Reference: {reference}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Co robi ambasador przy organizacji międzynarodowej?\n",
      "Prediction: a przy organizacji międzynarodowej?\"; \"art. 20.\"\n",
      "Reference: 1) reprezentuje Rzeczpospolitą Polską wobec organizacji, 2) utrzymuje łączność między Rzecząpospolitą Polską a organizacją, 3) prowadzi rokowania z organizacją i w ramach organizacji, 4) zaznajamia się z działalnością prowadzoną przez organizację i przekazuje właściwym organom władzy publicznej Rzeczypospolitej Polskiej informację na temat jej działalności, 5) zapewnia udział Rzeczypospolitej Polskiej w pracach organizacji, 6) chroni interesy Rzeczypospolitej Polskiej, jej obywateli oraz polskich osób prawnych w stosunkach z organizacją, 7) popiera realizację celów i zasad organizacji przez współpracę z organizacją i w ramach organizacji, 8) uczestniczy, poza granicami Rzeczypospolitej Polskiej oraz w zakresie przedmiotu działalności organizacji, w czynnościach przedstawicieli organów władzy publicznej w zakresie prowadzonych przez nich negocjacji i podejmowanych działań, zapewnia współdziałanie tych przedstawicieli, dba o zgodność ich czynności z założeniami polskiej polityki zagranicznej, a także udziela im pomocy i współdziała z nimi w zakresie ich zadań w stosunkach z organizacją\n",
      "Question: Czy funkcjonariusz celny może dostać odznakę honorową?\n",
      "Prediction: , który wzorowo wykonuje obowiązki?\n",
      "Reference: Tak\n",
      "Question: Co tworzy Skarb Państwa w celu przygotowania i wykonania przedsięwzięć Euro 2012?\n",
      "Prediction:  celowej... Art. 26.\n",
      "Reference: spółkami celowymi\n",
      "Question: Jaki organ dokonuje wymiaru i poboru opłaty celnej dodatkowej?\n",
      "Prediction:  celnych dodatkowych. Art. 28. Art. 28. celnych, Art. 29.\n",
      "Reference: naczelnik urzędu celnego\n",
      "Question: Na czyj wniosek rada ministrów określa tryb powierzania mienia kierownikom urzędów państwowych?\n",
      "Prediction: , o której mowa w art. 2 pkt 7... Rada Ministrów, na wniosek ministra,\n",
      "Reference: na wniosek Ministra Skarbu Państwa\n",
      "Question: Czy specjalne zezwolenie połowowe zawiera wykształcenie armatora statku rybackiego?\n",
      "Prediction:  połowów, o którym mowa w art. 15 ust.\n",
      "Reference: Nie\n",
      "Question: Jakiej karze podlega naruszanie czyjejś nietykalności cielesnej z powodu przynależności rasowej?\n",
      "Prediction: .. Art. 118. Kto narusza nietykalność cielesną\n",
      "Reference: podlega karze pozbawienia wolności od 3 miesięcy do lat 5\n",
      "Question: Z ilu osób składa się komisja przetargowa?\n",
      "Prediction: , w której skład wchodzi co najmniej trzech członków komisji.\n",
      "Reference: Komisja przetargowa składa się z co najmniej trzech osób.\n",
      "Question: Czy funkcjonariusz celny może dostać odznakę honorową?\n",
      "Prediction: , że funkcjonariusz celny może dostać odznakę honorową?\n",
      "Reference: Tak, za szczególne wyróżnienia\n",
      "Question: Jakie są zadania gmin w ramach prac związanych ze spisem?\n",
      "Prediction:  spisowych w gminach.. Spis powszechny w gminach. Spis powszechny w gminach. Spis powszechny w gminach. Spis powszechny.\n",
      "Reference: obowiązek zaktualizowania nazewnictwa ulic i placów oraz numeracji nieruchomości, ewidencji ludności, zaktualizowanie wykazów nieruchomości i mieszkań w wylosowanych obwodach spisowych, zorganizowanie przeprowadzenia we współdziałaniu z wojewódzkim urzędem statystycznym spisu na terenie gminy\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Analizując odpowiedzi modelu, można zauważyc pewne powtarzające się mankamenty. Przede wszystkim odpowiedzi modelu często są niepełne, urwane. Model ma tendencje do umieszczania w odpowiedzi fragmentów, które pojawiły się w pytaniu, a także numerów artykułów oraz powtarzania sekwencji tych samych słów lub symboli. Ponadto model generuje nadmiernie znaki  interpunkcyjne w miejscach, w których nie powinny się one pojawić, np. rozpoczynanie odpowiedzi od przecinka lub kropki. Model generował też nieoczekiwane symbole przypominające znaki z alfabetu chińskiego lub japońskiego, ale zostały one odflitrowane za pomocą wyrażenia regularnego dla zwiększenia czytelności. "
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best results on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T17:24:39.602176Z",
     "start_time": "2025-01-13T17:24:33.938522Z"
    }
   },
   "outputs": [],
   "source": [
    "example_metrics_test = compute_metrics_for_examples(predictions_test_text, references_test_text, test_dataset)\n",
    "\n",
    "df_metrics_test = pd.DataFrame(example_metrics_test)\n",
    "\n",
    "sorted_by_f1_test = df_metrics_test.sort_values(by=\"f1\", ascending=False)\n",
    "sorted_by_em_test = df_metrics_test.sort_values(by=\"exact_match\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T17:24:39.662047Z",
     "start_time": "2025-01-13T17:24:39.657697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 examples with highest f1:\n",
      "\n",
      "Example 354:\n",
      "Question: Jaki organ wydaje decyzję o uznaniu praktyki za ograniczającą konkurencję?\n",
      "Prediction:  Prezes Urzędu Ochrony Konkurencji i Konsumentów.\n",
      "Reference: Prezes Urzędu Ochrony Konkurencji i Konsumentów.\n",
      "f1: 100.00\n",
      "\n",
      "Example 300:\n",
      "Question: Kiedy została sporządzona Międzynarodowa Konwencja Przeciwko Braniu Zakładników?\n",
      "Prediction:  w dniu 18 grudnia 1979 r.\n",
      "Reference: w dniu 18 grudnia 1979 r.\n",
      "f1: 100.00\n",
      "\n",
      "Example 358:\n",
      "Question: Jeśli ustawa nie stanowi inaczej, w jakim postępowaniu dokonuje czynności prokurator?\n",
      "Prediction:  w postępowaniu przygotowawczym\n",
      "Reference: W postępowaniu przygotowawczym.\n",
      "f1: 100.00\n",
      "\n",
      "Example 326:\n",
      "Question: Kto wydaje decyzję o uznaniu praktyki za ograniczającą konkurencję?\n",
      "Prediction:  Prezes Urzędu Ochrony Konkurencji i Konsumentów.\n",
      "Reference: Prezes Urzędu Ochrony Konkurencji i Konsumentów\n",
      "f1: 100.00\n",
      "\n",
      "Example 192:\n",
      "Question: Czy w każdej gminie znajduje się wojewódzka biblioteka publiczna?\n",
      "Prediction:  w każdej gminie znajduje się wojewódzka biblioteka publiczna.\n",
      "Reference: Nie, nie w każdej gminie znajduje się wojewódzka biblioteka publiczna.\n",
      "f1: 88.89\n",
      "\n",
      "Example 379:\n",
      "Question: W którym okresie czasu wierni Kościoła mają prawo do zwolnienia od pracy i nauki na czas święta adwentystycznego?\n",
      "Prediction:  w piątek do zachodu słońca w sobotę.\n",
      "Reference: Od zachodu słońca w piątek do zachodu słońca w sobotę.\n",
      "f1: 82.35\n",
      "\n",
      "Example 121:\n",
      "Question: Do kiedy uważa się za spełniony wymóg odbycia aplikacji dyplomatyczno-konsularną?\n",
      "Prediction:  w terminie 5 lat od dnia wejścia w życie.\n",
      "Reference: do 5 lat od dnia wejścia ustawy w życie\n",
      "f1: 77.78\n",
      "\n",
      "Example 69:\n",
      "Question: Czy w każdej gminie musi znajdować się biblioteka publiczna?\n",
      "Prediction:  w każdej gminie musi znajdować się biblioteka publiczna.\n",
      "Reference: Tak, w każdej gminie musi znajdować się co najmniej jedna gminna biblioteka publiczna\n",
      "f1: 76.19\n",
      "\n",
      "Example 17:\n",
      "Question: Czy spółka może udzielać pożyczek na nabycie emitowanych przez nią akcji?\n",
      "Prediction:  może udzielać pożyczek na nabycie akcji?\n",
      "Reference: Nie, Spółka nie może udzielać pożyczek na nabycie emitowanych przez nią akcji.\n",
      "f1: 66.67\n",
      "\n",
      "Example 228:\n",
      "Question: Kto sprawuje nadzór nad Akademią?\n",
      "Prediction: .. Minister właściwy do spraw\n",
      "Reference: minister właściwy\n",
      "f1: 66.67\n"
     ]
    }
   ],
   "source": [
    "display_top_examples(sorted_by_f1_test, 'f1', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T17:24:39.723458Z",
     "start_time": "2025-01-13T17:24:39.720037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 examples with highest exact_match:\n",
      "\n",
      "Example 326:\n",
      "Question: Kto wydaje decyzję o uznaniu praktyki za ograniczającą konkurencję?\n",
      "Prediction:  Prezes Urzędu Ochrony Konkurencji i Konsumentów.\n",
      "Reference: Prezes Urzędu Ochrony Konkurencji i Konsumentów\n",
      "exact_match: 100.00\n",
      "\n",
      "Example 358:\n",
      "Question: Jeśli ustawa nie stanowi inaczej, w jakim postępowaniu dokonuje czynności prokurator?\n",
      "Prediction:  w postępowaniu przygotowawczym\n",
      "Reference: W postępowaniu przygotowawczym.\n",
      "exact_match: 100.00\n",
      "\n",
      "Example 354:\n",
      "Question: Jaki organ wydaje decyzję o uznaniu praktyki za ograniczającą konkurencję?\n",
      "Prediction:  Prezes Urzędu Ochrony Konkurencji i Konsumentów.\n",
      "Reference: Prezes Urzędu Ochrony Konkurencji i Konsumentów.\n",
      "exact_match: 100.00\n",
      "\n",
      "Example 300:\n",
      "Question: Kiedy została sporządzona Międzynarodowa Konwencja Przeciwko Braniu Zakładników?\n",
      "Prediction:  w dniu 18 grudnia 1979 r.\n",
      "Reference: w dniu 18 grudnia 1979 r.\n",
      "exact_match: 100.00\n",
      "\n",
      "Example 387:\n",
      "Question: zamawiający może udzielić zamówienia w trybie zapytania o cenę?\n",
      "Prediction: . Art. 69.. Zamawiający\n",
      "Reference: Zamawiający może udzielić zamówienia w trybie zapytania o cenę, jeżeli przedmiotem zamówienia są dostawy lub usługi powszechnie dostępne o ustalonych standardach jakościowych, a wartość zamówienia jest mniejsza niż kwoty określone w przepisach wydanych na podstawie art. 11 ust. 8 ustawy Pzp\n",
      "exact_match: 0.00\n"
     ]
    }
   ],
   "source": [
    "display_top_examples(sorted_by_em_test, 'exact_match', 5)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T15:02:10.828609Z",
     "start_time": "2025-01-17T15:02:10.819531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "comparison_data = {\n",
    "    'Metric': ['Exact Match', 'F1'],\n",
    "    'Validation': [metrics['exact_match'], metrics['f1']],\n",
    "    'Test': [metrics_test['exact_match'], metrics_test['f1']]\n",
    "}\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(comparison_df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Metric  Validation     Test\n",
      "0  Exact Match    0.099150  0.69808\n",
      "1           F1    4.577592  9.06427\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions \n",
    "\n",
    "1. Does the performance on the validation dataset reflects the performance on your test set?\n",
    "   \n",
    "   Model osiągnął lepsze wyniki na zbiorze testowym niż na zbiorze walidacyjnym, co jest dość zaskakujące, jednak w obu przypadkach wyniki pozostawiały wiele do życzenia. W przypadku zbioru walidacyjnego metryki *F1* i *exact match* wyniosły odpowiednio: 4.6 i 0.1, natomiast w przypadku zbioru testowego *F1* osiągnęło wartość 9.1, a *exact_match* 0.7. Lepsze wyniki modelu na zbiorze testowym mogą wynikać z kilku czynników, związanych z chcarakterystyką obu zbiorów. Zbiór testowy jest bardziej jednorodny - wszystkie pytania dotyczą przepisów prawa, natomiast w zbiorze walidacyjnym mamy pytania z wielu różnych dziedzin. Podobnie w przypadku kontekstów w zbiorze PoQuAD teksty są bardziej zróżnicowane, zarówno pod względem treści, jak i formy, co przekłada się także na odpowiedzi, które również mocno się od siebie rożnią (długością, treścią, formą). Natomiast w przypadku zbioru Simple legal questions wszystkie konteksty są cytatami z przepisów prawa, a więc są bardziej spójne. Podobnie rzecz się ma jeśli chodzi o odpowiedzi. Często ta sama odpowiedź pasuje do wielu pytań. Te czynniki mogą sprawiać, że odpowiadnie na pytania ze zbioru testowego jest dla modelu nieco łatwiejsze. Należy również wziąć pod uwagę znaczące różnice w liczebności obu zbiorów (zbiór walidacyjny - ponad 7 tys. przykładów, zbiór testowy - niecałe 600 przykładów).\n",
    "2. What are the outcomes of the model on your test questions? Are they satisfying? If not, what might be the reason\n",
    "   for that?\n",
    "\n",
    "   Odpowiedzi modelu pozostawiają wiele do życzenia. Model ma tendencję do generowania nieoczekiwanych symboli, przypominających znaki z alfabetu chińskiego lub japońskiego (usunięte za pomocą wyrażenie regularnego dla zwiększenia czytelności) oraz znaków interpunkcyjnych w miejscach, w których nie powinny się one pojawić, np. kropki i przecinki na początku odpowiedzi, odpowiedzi zakończone znakiem zapytania. Poza tym model często generuje odpowiedzi niepełne, urwane lub generuje ciągi tych samych słów lub znaków. Sądzę, że opisane mankamenty wynikają przede wszystkim z ograniczeń związanych z trenowaniem modelu, takich jak ograniczone zasoby sprzętowe, czas, zbiór danych. Ze względu na wspomniane ograniczenia model trenowany był tylko przez 2 epoki. Natomiast zadanie generatywnego odpowiadania na pytania jest zadaniem trudnym, często wymaga zdolności pewnego rodzaju \"rozumowania\", np. w pytananiach zaczynających się od \"czy\", które wymagają zrozumienia kontekstu, aby udzielić odpowiedzi \"tak\" lub \"nie\", która nie pada bezpośrednio. Trening, który byłam w sptanie przeprowadzić na dostępnuch zasobach, mógł okazać się niewystarczający do tego zadania. \n",
    "3. Why extractive question answering is not well suited for inflectional languages?\n",
    "\n",
    "   Ekstrakcyjne odpowiadanie na pytania nie jest odpowiednie dla języków fleksyjnych ze względu na różnorodność form, w jakich mogą występować wyrazy. Konkretne pytanie determinuje użycie określonych form wyrazów w odpowiedzi, często różnych od tych użytych w kontekście. Proste wycinanie fragmentów kontekstu i umieszczanie ich jako odpowiedzi skutkowałoby tworzeniem wypowiedzi niepoprawnych gramatycznie. "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6460084,
     "sourceId": 10422631,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "morfeusz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
