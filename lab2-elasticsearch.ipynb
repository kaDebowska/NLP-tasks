{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Elastic Search\n",
    "1. Install ElasticSearch (ES).\n",
    "2. Install an ES plugin for Polish https://github.com/allegro/elasticsearch-analysis-morfologik \n",
    "3. Define an ES analyzer for Polish texts containing:\n",
    "   1. standard tokenizer\n",
    "   2. synonym filter with alternative forms for months, e.g. `kwiecień`, `kwi`, `IV`.\n",
    "   3. lowercase filter\n",
    "   4. Morfologik-based lemmatizer\n",
    "   5. lowercase filter (looks strange, but Morfologi produces capitalized base forms for proper names, so we have to lowercase them once more).\n",
    "4. Define another analyzer for Polish, without the synonym filter.\n",
    "5. Define an ES index for storing the contents of the corpus [FiQA-PL](https://huggingface.co/datasets/clarin-knext/fiqa-pl) using both analyzers.\n",
    "   Use different names for the fields analyzed with a different pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\katar\\miniconda3\\envs\\NLP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'number': '8.15.3',\n",
       " 'build_flavor': 'default',\n",
       " 'build_type': 'zip',\n",
       " 'build_hash': 'f97532e680b555c3a05e73a74c28afb666923018',\n",
       " 'build_date': '2024-10-09T22:08:00.328917561Z',\n",
       " 'build_snapshot': False,\n",
       " 'lucene_version': '9.11.1',\n",
       " 'minimum_wire_compatibility_version': '7.17.0',\n",
       " 'minimum_index_compatibility_version': '7.0.0'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "username = os.getenv('ES_USERNAME')\n",
    "password = os.getenv('ES_PASSWORD')\n",
    "\n",
    "es = Elasticsearch(\n",
    "    \"http://localhost:9200\",\n",
    "    http_auth=(username, password)\n",
    ")\n",
    "\n",
    "es.info()['version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'fiqa-pl-corpus'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_config = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"tokenizer\": {\n",
    "                \"standard_tokenizer\": {\n",
    "                    \"type\": \"standard\"\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"polish_synonyms\": {\n",
    "                    \"type\": \"synonym\",\n",
    "                    \"synonyms\": [\n",
    "                        \"styczeń, sty, I\",\n",
    "                        \"luty, lut, II\",\n",
    "                        \"marzec, mar, III\",\n",
    "                        \"kwiecień, kwi, IV\",\n",
    "                        \"maj, V\",\n",
    "                        \"czerwiec, cze, VI\",\n",
    "                        \"lipiec, lip, VII\",\n",
    "                        \"sierpień, sie, VIII\",\n",
    "                        \"wrzesień, wrz, IX\",\n",
    "                        \"październik, paź, X\",\n",
    "                        \"listopad, lis, XI\",\n",
    "                        \"grudzień, gru, XII\"\n",
    "                    ]\n",
    "                },\n",
    "\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"polish_analyzer_with_synonyms\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard_tokenizer\",\n",
    "                    \"filter\": [\n",
    "                        \"polish_synonyms\",\n",
    "                        \"lowercase\",\n",
    "                        \"morfologik_stem\",\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                },\n",
    "                \"polish_analyzer_without_synonyms\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard_tokenizer\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"morfologik_stem\",\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"content_with_synonyms\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"polish_analyzer_with_synonyms\"\n",
    "            },\n",
    "            \"content_without_synonyms\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"polish_analyzer_without_synonyms\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "index_name = \"fiqa-pl-corpus\"\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "es.indices.create(index=index_name, body=index_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Load the data to the ES index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"clarin-knext/fiqa-pl\", \"corpus\")['corpus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57638, [])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_documents(dataset):\n",
    "    for item in dataset:\n",
    "        yield {\n",
    "            \"_index\": \"fiqa-pl-corpus\",\n",
    "            \"_source\": {\n",
    "                \"content_with_synonyms\": item[\"text\"],\n",
    "                \"content_without_synonyms\": item[\"text\"]\n",
    "            }\n",
    "        }\n",
    "\n",
    "helpers.bulk(es, generate_documents(dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Determine the number of documents and the number of matches containing the word kwiecień (in any form) including and excluding the synonyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents containing 'kwiecień' (with synonyms): 306\n",
      "Documents containing 'kwiecień' (without synonyms): 257\n"
     ]
    }
   ],
   "source": [
    "with_synonyms_count = es.count(index=\"fiqa-pl-corpus\", body={\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"content_with_synonyms\": \"kwiecień\"\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "without_synonyms_count = es.count(index=\"fiqa-pl-corpus\", body={\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"content_without_synonyms\": \"kwiecień\"\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "print(f\"Documents containing 'kwiecień' (with synonyms): {with_synonyms_count['count']}\")\n",
    "print(f\"Documents containing 'kwiecień' (without synonyms): {without_synonyms_count['count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents containing 'kwi': 3\n",
      "Documents containing 'IV': 47\n"
     ]
    }
   ],
   "source": [
    "documents_with_kwi = es.count(index=\"fiqa-pl-corpus\", body={\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"content_without_synonyms\": \"kwi\"\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "documents_with_IV = es.count(index=\"fiqa-pl-corpus\", body={\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"content_without_synonyms\": \"IV\"\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "print(f\"Documents containing 'kwi': {documents_with_kwi['count']}\")\n",
    "print(f\"Documents containing 'IV': {documents_with_IV['count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents containing both 'kwiecień' and 'kwi': 1\n"
     ]
    }
   ],
   "source": [
    "documents_with_kwiecien_and_kwi = es.count(index=\"fiqa-pl-corpus\", body={\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\"match\": {\"content_without_synonyms\": \"kwiecień\"}},\n",
    "                {\"match\": {\"content_without_synonyms\": \"kwi\"}}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "print(f\"Documents containing both 'kwiecień' and 'kwi': {documents_with_kwiecien_and_kwi['count']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suma dokumantów zawierających kwiecień (bez synonimów), kwi oraz IV jest o 1 większa niż liczba dokumntów zawierających kwiecień z synonimami. Wynika to z faktu, że istnieje dokument, w którym występują dwie formy wyrazu - kwiecień i kwi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Download the QA pairs for the FiQA-PL dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = load_dataset(\"clarin-knext/fiqa-pl\", \"queries\")['queries'].to_pandas()\n",
    "\n",
    "qrels = load_dataset(\"clarin-knext/fiqa-pl-qrels\")['test'].to_pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Compute NDCG@5 for the QA dataset (the test subset) for the following setusp:\n",
    "   * synonyms enabled and disabled,\n",
    "   * lemmatization in the query enabled and disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'qa_index_nodcg'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_body = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"filter\": {\n",
    "                \"polish_synonym\": {\n",
    "                    \"type\": \"synonym\",\n",
    "                    \"synonyms\": [\n",
    "                        \"styczeń, sty, I\",\n",
    "                        \"luty, lut, II\",\n",
    "                        \"marzec, mar, III\",\n",
    "                        \"kwiecień, kwi, IV\",\n",
    "                        \"maj, V\",\n",
    "                        \"czerwiec, cze, VI\",\n",
    "                        \"lipiec, lip, VII\",\n",
    "                        \"sierpień, sie, VIII\",\n",
    "                        \"wrzesień, wrz, IX\",\n",
    "                        \"październik, paź, X\",\n",
    "                        \"listopad, lis, XI\",\n",
    "                        \"grudzień, gru, XII\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"analyzer_with_synonyms_and_lemmas\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"polish_synonym\",\n",
    "                        \"lowercase\",\n",
    "                        \"morfologik_stem\",\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                },\n",
    "                \"analyzer_with_synonyms_without_lemmas\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"polish_synonym\",\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                },\n",
    "                \"analyzer_without_synonyms_with_lemmas\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"morfologik_stem\",\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                },\n",
    "                \"analyzer_without_synonyms_and_lemmas\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"analyzer_without_synonyms_and_lemmas\"\n",
    "            },\n",
    "            \"text_synonyms_lemmas\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"analyzer_with_synonyms_and_lemmas\"\n",
    "            },\n",
    "            \"text_synonyms\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"analyzer_with_synonyms_without_lemmas\"\n",
    "            },\n",
    "            \"text_lemmas\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"analyzer_without_synonyms_with_lemmas\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"qa_index_nodcg\"\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "es.indices.create(index=\"qa_index_nodcg\", body=index_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57638, [])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = dataset.map(lambda item: {\n",
    "    \"_op_type\": \"index\",\n",
    "    \"_index\": \"qa_index_nodcg\",\n",
    "    \"_source\": {\n",
    "        \"text\": item[\"text\"], \n",
    "        \"text_synonyms_lemmas\": item[\"text\"],\n",
    "        \"text_synonyms\": item[\"text\"], \n",
    "        \"text_lemmas\": item[\"text\"],\n",
    "        \"id\": item[\"_id\"] \n",
    "    }\n",
    "}).to_list()\n",
    "\n",
    "helpers.bulk(es, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(query, analyzer, field):\n",
    "    response = es.search(\n",
    "        index=\"qa_index_nodcg\",\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    field: {\n",
    "                        \"query\": query,\n",
    "                        \"analyzer\": analyzer\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"size\": 5\n",
    "        }\n",
    "    )\n",
    "    return [hit[\"_id\"] for hit in response[\"hits\"][\"hits\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def count_ndcg5(answers, correct_answers):\n",
    "    DCG = sum(\n",
    "    1 / math.log(i + 2, 2) for i in range(5) if int(answers[i]) in correct_answers\n",
    "    )\n",
    "    IDCG = sum(\n",
    "        1 / math.log(i + 2, 2) for i in range(min(len(correct_answers), 5))\n",
    "    )\n",
    "\n",
    "    return DCG / IDCG if IDCG > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "analyzers = {\"analyzer_with_synonyms_and_lemmas\": \"text_synonyms_lemmas\",\n",
    "             \"analyzer_with_synonyms_without_lemmas\": \"text_synonyms\",\n",
    "             \"analyzer_without_synonyms_with_lemmas\": \"text_lemmas\",\n",
    "             \"analyzer_without_synonyms_and_lemmas\": \"text\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_answers(query):\n",
    "    answers = {}\n",
    "    for analyzer, field in analyzers.items():\n",
    "        answers[analyzer] = execute_query(query, analyzer, field)\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_results(answers, ids_correct):\n",
    "    values = {}\n",
    "    for analyzer, result in answers.items():\n",
    "        values[analyzer] = count_ndcg5(result, ids_correct)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzer_with_synonyms_and_lemmas: 0.1851291130797741\n",
      "analyzer_with_synonyms_without_lemmas: 0.13854570378524392\n",
      "analyzer_without_synonyms_with_lemmas: 0.1851291130797741\n",
      "analyzer_without_synonyms_and_lemmas: 0.13854570378524392\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for id in qrels[\"query-id\"].unique():\n",
    "    question = queries[queries['_id'] == str(id)][\"text\"].to_list()[0]\n",
    "    answers = find_answers(question)\n",
    "    \n",
    "    res = calculate_results(answers, qrels[qrels[\"query-id\"] == id][\"corpus-id\"].to_list())\n",
    "    results.append(res)\n",
    "\n",
    "result_values = {key: [] for key in analyzers.keys()}\n",
    "\n",
    "for res in results:\n",
    "    for key in analyzers.keys():\n",
    "        result_values[key].append(res[key])\n",
    "\n",
    "for key in analyzers.keys():\n",
    "    mean_value = np.mean(result_values[key])\n",
    "    print(f\"{key}: {mean_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uwzględnienie synonimów nie wpłynęło na wyniki, natomiast lematyzacja poprawia wyniki wyszukiwania."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the strengths and weaknesses of regular expressions versus full text search regarding processing of text?\n",
    "\n",
    "Wyrażenia regularne mogą być łatwiejsze i szybsze w użyciu w przypadku dobrze zdefiniowanych wzorców, które występują w ściśle określonej formie, jak np. adresy email, godziny. Problem pojawia się, gdy musimy rozważyć wiele form, uwzględnić odmianę wyrazów czy synonimy. Wówczas zdecydowanie lepszym rozwiązaniem będzie wyszukiwanie pełnotekstowe, które oferuje znacznie szersze możliwości, takie jak lematyzacja, obsługa synonimów oraz wyszukiwanie z tolerancją na błędy, co pozwala na bardziej elastyczne wyszukiwanie, niewymagające ręcznego wypisywania wszystkich możliwych form. Poza tym wyszukiwanie pełnotekstowe umożliwia bardziej kontekstowe przeszukiwanie dokumentów, jak np. wyszukiwanie odpowiedzi na pytania, gdzie nie szukamy dokładnego dopasowania wzrorca, a potrzebujemy uwzględnić bliskość znaczeniową.\n",
    "\n",
    "### Can an LLM be applied in the context of searching for documents? Justify your answer, excluding the obvious observation that an LLM can be used to formulate the answer.\n",
    "\n",
    "Tak, LLM może być wykorzystany do wyszukiwania dokumentów. Podobnie jak w przypadku Elasticsearcha, możemy stworzyć indeks dokumentów, przekształcić go na postać wektorową, która stanowi reprezentację semantyczną, a następnie przekazać taki indeks do modelu. Modele językowe są w stanie przeszukiwać ten indeks i zwracać dokumenty najistotniejsze dla naszego zapytania. Modele potrafią rozpoznawać i dopasowywać zapytania do dokumentów na poziomie semantycznym, a nie tylko leksykalnym, co oznacza, że mogą znaleźć odpowiednie dokumenty, nawet jeśli nie zawierają tych samych fraz co zapytanie. LLM są też zdolne do identyfikacji kluczowych informacji w dokumentach i tworzenia streszczeń czy klasyfikacji.  Możemy też prosić model, aby zwrócił nam dokumenty, na podstawie których wygenerował odpowiedź, dzięki czemu jesteśmy w stanie zweryfikować jej poprawność."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
