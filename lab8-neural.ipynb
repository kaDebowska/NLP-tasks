{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural search for question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install 'farm-haystack[all]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:05:28.447762Z",
     "iopub.status.busy": "2025-01-03T22:05:28.447419Z",
     "iopub.status.idle": "2025-01-03T22:05:28.451924Z",
     "shell.execute_reply": "2025-01-03T22:05:28.451063Z",
     "shell.execute_reply.started": "2025-01-03T22:05:28.447734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from haystack.nodes import EmbeddingRetriever\n",
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "from haystack import Document\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T19:11:04.534098Z",
     "iopub.status.busy": "2025-01-03T19:11:04.533871Z",
     "iopub.status.idle": "2025-01-03T19:11:13.661257Z",
     "shell.execute_reply": "2025-01-03T19:11:13.660559Z",
     "shell.execute_reply.started": "2025-01-03T19:11:04.534078Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720844f4e1e443798c029df14c6583e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4468b44b054929b74ab8087cfaab61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e33f9696524fc2af4bb23b4948eebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56bdd4422bb94b0ebf3e29142be1a76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6c86d878434c2496415095eb905326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d754df7cbf490384acf9928cb2b9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_store = InMemoryDocumentStore(\n",
    "    similarity=\"cosine\",\n",
    "    embedding_dim=768\n",
    ")\n",
    "\n",
    "e5 = EmbeddingRetriever(\n",
    "    document_store=doc_store,\n",
    "    embedding_model=\"intfloat/multilingual-e5-base\",\n",
    "    model_format=\"transformers\", \n",
    "    pooling_strategy=\"reduce_mean\",\n",
    "    top_k=5,\n",
    "    max_seq_len=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T19:11:13.662412Z",
     "iopub.status.busy": "2025-01-03T19:11:13.662144Z",
     "iopub.status.idle": "2025-01-03T19:11:22.147564Z",
     "shell.execute_reply": "2025-01-03T19:11:22.146782Z",
     "shell.execute_reply.started": "2025-01-03T19:11:13.662388Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c6f3e2dd4c41fea03b9deee545d5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/201 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4514f54d4045b9be5fa8b9d654d6c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fiqa-pl.py:   0%|          | 0.00/1.67k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d20338009c4441b92d638391610333c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0000.parquet:   0%|          | 0.00/32.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015603ddb9e547c7867ff91c2c37d9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating corpus split:   0%|          | 0/57638 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6d93e0a93a4853bc58f86e00aa161a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0000.parquet:   0%|          | 0.00/377k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20dddab6d2ff4019b22936a3ccfcbbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating queries split:   0%|          | 0/6648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aeeeb2759e94c3ea3925ba8dcbab5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/201 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13f71317c5c4e04b2d4636b81f8d40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.tsv:   0%|          | 0.00/210k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7360468184704152b7764119612e09b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev.tsv:   0%|          | 0.00/18.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a8ecea9ceb4bfdb077a9bfebb6e052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.tsv:   0%|          | 0.00/25.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be13d571dc3a4c77b56325e671fe1d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/14166 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandas/io/common.py:131: ResourceWarning: unclosed file <_io.BufferedReader name='/root/.cache/huggingface/hub/datasets--clarin-knext--fiqa-pl-qrels/snapshots/11adceb9cbc24a6462532316290250b0afe91c4b/train.tsv'>\n",
      "  self.handle.detach()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358b21d648b948519738f6473ac18bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1238 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandas/io/common.py:131: ResourceWarning: unclosed file <_io.BufferedReader name='/root/.cache/huggingface/hub/datasets--clarin-knext--fiqa-pl-qrels/snapshots/11adceb9cbc24a6462532316290250b0afe91c4b/dev.tsv'>\n",
      "  self.handle.detach()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0aa696688ca4c309c1512190f6c45ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1706 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandas/io/common.py:131: ResourceWarning: unclosed file <_io.BufferedReader name='/root/.cache/huggingface/hub/datasets--clarin-knext--fiqa-pl-qrels/snapshots/11adceb9cbc24a6462532316290250b0afe91c4b/test.tsv'>\n",
      "  self.handle.detach()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "corpus = load_dataset(\"clarin-knext/fiqa-pl\", \"corpus\")['corpus']\n",
    "queries = load_dataset(\"clarin-knext/fiqa-pl\", \"queries\")['queries']\n",
    "qrels = load_dataset(\"clarin-knext/fiqa-pl-qrels\")['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T19:13:36.328942Z",
     "iopub.status.busy": "2025-01-03T19:13:36.328641Z",
     "iopub.status.idle": "2025-01-03T19:13:53.112990Z",
     "shell.execute_reply": "2025-01-03T19:13:53.112328Z",
     "shell.execute_reply.started": "2025-01-03T19:13:36.328921Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "docs = []\n",
    "for doc in corpus:\n",
    "    docs.append(\n",
    "        Document(content=doc[\"text\"], meta={\"title\": doc[\"title\"], \"pmid\": int(doc[\"_id\"])})\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "doc_store.write_documents(docs)\n",
    "doc_store.update_embeddings(e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:23:07.577874Z",
     "iopub.status.busy": "2025-01-03T20:23:07.577590Z",
     "iopub.status.idle": "2025-01-03T20:23:07.977675Z",
     "shell.execute_reply": "2025-01-03T20:23:07.976676Z",
     "shell.execute_reply.started": "2025-01-03T20:23:07.577854Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a62ab721a2f42f0bf00b58a0729ad56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "queries = queries.map(lambda x: {**x, \"_id\": int(x[\"_id\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:53:59.723893Z",
     "iopub.status.busy": "2025-01-03T20:53:59.723540Z",
     "iopub.status.idle": "2025-01-03T20:53:59.729406Z",
     "shell.execute_reply": "2025-01-03T20:53:59.728567Z",
     "shell.execute_reply.started": "2025-01-03T20:53:59.723866Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def count_ndcg(answers, correct_answers, size):\n",
    "    DCG = 0\n",
    "    for i in range(min(len(answers), size)):\n",
    "        if int(answers[i]) in correct_answers:\n",
    "            DCG += 1 / math.log(i + 2, 2)\n",
    "\n",
    "    IDCG = sum(\n",
    "        1 / math.log(i + 2, 2) for i in range(min(len(correct_answers), size))\n",
    "    )\n",
    "    return DCG / IDCG if IDCG > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "unique_query_ids = set(qrels['query-id'])\n",
    "results = []\n",
    "\n",
    "for query_id in unique_query_ids:\n",
    "    question = queries.filter(lambda x: x['_id'] == query_id)['text'][0]\n",
    "    correct_ids = qrels.filter(lambda x: x['query-id'] == query_id)['corpus-id']\n",
    "    retrieved_docs = e5.retrieve(question, top_k=5)\n",
    "    retrieved_ids = [int(doc.meta[\"pmid\"]) for doc in retrieved_docs]\n",
    "    ndcg_score = count_ndcg(retrieved_ids, correct_ids, 5)\n",
    "    results.append(ndcg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:06:04.009083Z",
     "iopub.status.busy": "2025-01-03T22:06:04.008757Z",
     "iopub.status.idle": "2025-01-03T22:06:04.014453Z",
     "shell.execute_reply": "2025-01-03T22:06:04.013667Z",
     "shell.execute_reply.started": "2025-01-03T22:06:04.009056Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG@5: 0.21391997473307967\n"
     ]
    }
   ],
   "source": [
    "mean_ndcg = np.mean(results)\n",
    "print(f\"Mean NDCG@5: {mean_ndcg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uzyskana wartość NDCG (0.21) jest zdecydowanie lepsza niż we wcześniejszych metodach. W przypadku ElasticSearcha było to ok. 0.18, a w przypadku modelu z laboratorium 5 - zaledwie 0.13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. Which of the methods: lexical match (e.g. ElasticSearch) or dense representation works better?\n",
    "   \n",
    "   Biorąc pod uwagę wartości NDCG, dense representation przewyższa metody leksykalne, takie jak ElasticSearch. Poza tym framework Haystack okazał się zdecydowanie łatwiejszy w użyciu w porównaiu z ElasticSearchem.\n",
    "\n",
    "2. Which of the methods is faster?\n",
    "   \n",
    "   Pod względem szybkości ElsticSearch znacznie przewyższa metody neuronowe, które są zdecydowanie bardziej skomplikowane, przez co wymagają większych zasobów i dłuższego czasu przetwarzania. \n",
    "\n",
    "3. Try to determine the other pros and cons of using lexical search and dense document retrieval models.\n",
    "\n",
    "   Niewątpliwymi zaletami metod leksykalnych są szybkość i mniejsze wymagania sprzętowe, ponieważ ElsticSearch nie wymaga GPU. Po stronie plusów można zapisać również interpretowalność. Modele leksykalne opierają się na dopasowywaniu słów kluczowych, a więc są łatwiejsze do zrozumienia.\n",
    "\n",
    "   Dużym minusem metod opartych na wyszukianiu leksykalnym jest brak semantycznego rozumienia, przez co modele te nie nadają się do zadań wymagających rozumienia kontekstu.\n",
    "\n",
    "   W przypadku modeli gęstych reprezentacji ich największą zaletą jest rozumienie kontekstu zapytań i dokumentów, co pozwala na wychwycenie relacji niezrozumiałych dla modeli leksykalnych. Kolejną zaletą modeli typu `dense retrival` jest wsparcie dla wielojęzyczności, która pozwala na łatwe przetwarzanie dokumentów w różnych językach, podczas dy w przypadku ElastcSearch potrzebne są  stemmery i tokenizatory.\n",
    "\n",
    "   Po stronie wad modeli takich jak E5 można zapisać większe koszty obliczeniowe i większe wymagania sprzętowe, wolniejsze przetwarzanie oraz  mniejszą intepretowalność. \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
